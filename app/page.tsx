'use client';

import React, { useState, useRef } from 'react';
import SummaryTodoButton from '@/components/SummaryTodoButton';
import WordListManager from './components/WordListManager';
import Header from './components/Header';
import '@/styles/main.css';

declare global {
  interface Window {
    SpeechRecognition: any;
    webkitSpeechRecognition: any;
  }
}

const HomePage = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState<string>('');
  const [wordList, setWordList] = useState<Record<string, string>>({});
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const recognitionRef = useRef<any>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  const handleRecordClick = () => {
    if (isRecording) {
      // ğŸ”´ éŒ²éŸ³ & æ–‡å­—èµ·ã“ã—ã‚’åœæ­¢
      recognitionRef.current?.stop();
      mediaRecorderRef.current?.stop();
      setIsRecording(false);
    } else {
      // ğŸ¤ éŒ²éŸ³é–‹å§‹
      startRecording();
      setIsRecording(true);
    }
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // ğŸ™ éŸ³å£°èªè­˜
      const SpeechRecognitionAPI = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognitionAPI) {
        alert('ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯ Web Speech API ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚');
        return;
      }

      const recognition = new SpeechRecognitionAPI();
      recognition.lang = 'ja-JP';
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.onresult = (event: any) => {
        let fullTranscript = '';
        for (let i = 0; i < event.results.length; i++) {
          fullTranscript += event.results[i][0].transcript;
        }
        setTranscript(fullTranscript);
      };

      recognitionRef.current = recognition;
      recognition.start();

      // ğŸ¤ ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ¬ã‚³ãƒ¼ãƒ€ãƒ¼
      const mediaRecorder = new MediaRecorder(stream);
      audioChunksRef.current = [];
      mediaRecorder.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data);
      };

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/mp3' });
        const url = URL.createObjectURL(audioBlob);
        setAudioUrl(url);
      };

      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start();
    } catch (error) {
      console.error('éŒ²éŸ³ã‚¨ãƒ©ãƒ¼:', error);
    }
  };

  // ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°
  const downloadAudio = () => {
    if (!audioUrl) return;
    const a = document.createElement('a');
    a.href = audioUrl;
    a.download = 'recording.mp3';
    a.click();
  };

  return (
    <div style={{ textAlign: 'center' }}>
      <Header />
      <button className='record-button' onClick={handleRecordClick}>
        {isRecording ? 'éŒ²éŸ³åœæ­¢' : 'éŒ²éŸ³é–‹å§‹'}
      </button>

      <p className='record-text'>{transcript}</p>

      {/* å˜èªãƒªã‚¹ãƒˆç®¡ç†ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ */}
      <WordListManager onUpdate={setWordList} />

      {/* ğŸ“ è¦ç´„ & TODO æŠ½å‡º */}
      <SummaryTodoButton transcript={transcript} wordList={wordList} />

      {/* ğŸµ éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ */}
      {audioUrl && (
        <div style={{ marginTop: '20px' }}>
          <h3>éŒ²éŸ³å®Œäº†</h3>
          <button
            onClick={downloadAudio}
            style={{
              padding: '10px 20px',
              fontSize: '16px',
              backgroundColor: 'purple',
              color: 'white',
              border: 'none',
              borderRadius: '8px',
              cursor: 'pointer',
            }}
          >
            éŸ³å£°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          </button>
        </div>
      )}
    </div>
  );
};

export default HomePage;
